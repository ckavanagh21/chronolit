{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Jared Simpauco\n",
    "- Colin Kavanagh\n",
    "- Darren Jiang\n",
    "- Chester Ni\n",
    "- Jack Howe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we create a model to determine an author’s birth year based on excerpts of their written published literature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For our project, we plan to create a model that can estimate the time period an author was born in based on the type of text used in their published written literature. We believe this would be an interesting project to attempt as the way text is written and stylized can vary between time periods. While it is not a well-documented or widely explored field, there have been attempts to address similar problems in authorship attribution, age detection from text, and author profiling. However, estimating an author's birth year directly from text is a more specific and nuanced problem. For our report, we plan to pull random passages from Project Gutenberg, which is a non-profit online library of free eBooks. This will act as our dataset and allow us to get a wide variety of published literature to gather data from. \n",
    "We found a few articles that may support our research question and help prove the validity of our project. According to the article Review of age and gender detection methods based on handwriting analysis by Fahimeh Alaei & Alireza Alaei, “developing an automated handwriting analysis system to detect a gender or age category from handwriting samples involves two stages, developing and training a model and then testing the trained model”(Alaei). While analysis of handwriting is different from analysis of text, being able to discern the difference in age based on one’s handwriting is something we plan to use in the creation of our own model. Additionally, the creation of our model is proven to be possible as if a model can determine one's age based on handwriting, another model could determine one’s age based on the type of font used during a given time period. Another article that supports our project is Age Detection in Chat by Jenny Tam and Craig H. Martell. Using Naive Bayes Classifier(NBC), they tested for differences in text length, emoticon usage, and punctuation to determine the person's age. They found that “As she compared teens against older and older age groups, however, her results monotonically increased until generating an f-score measure of 0.932 for teens against 50 year olds”(Tam & Martell). This research proves that there is a significant difference between younger and older generations texting as the test they made was highly accurate. Given their research was done during the same time period there is a possibility that we can create a model that can detect these differences between varying time periods.\n",
    "Alaei, F., Alaei, A. Review of age and gender detection methods based on handwriting analysis. Neural Comput & Applic 35, 23909–23925 (2023). https://doi.org/10.1007/s00521-023-08996-x\n",
    "J. Tam and C. H. Martell, \"Age Detection in Chat,\" 2009 IEEE International Conference on Semantic Computing, Berkeley, CA, USA, 2009, pp. 33-39, doi: 10.1109/ICSC.2009.37.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on preliminary research, we hypothesize that the language models we work with will be able to find some amount of correlation between the style of writing within samples of literature and the time period in which they were written. The English language has and continues to evolve over time, and certain trends may manifest within grammatical structures and vocabulary. However, we are aware that many factors could affect our ability to accurately predict the time period associated with the literature – for instance, translated texts may stylistically be more similar to other texts from the period of time when they were translated, as opposed to the period of time during which they were written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal dataset to answer our questions should contain excerpts of text, and ample metadata for each excerpt. Aside from the text itself, we would ideally have access to variables such as date of publication, genre of text, author, date of birth/death of author, country of origin of author, and country of publication. It would be easiest to work with this data if they were stored in a semi-structured format (such as JSON or XML) so that we can easily compile everything into something like a Pandas DataFrame. The excerpt itself can be stored with the metadata or separately as plain text.\n",
    "\n",
    "We would like to have as many observations as possible that we could work with, but a minimum of around 1000 seems like a solid starting point. With this number, we would have a large enough dataset to train models on, while also keeping few enough observations that it would be relatively easy to conduct EDA and feasible, if necessary, to manually comb through data points to handle obvious issues (i.e. with missing data). Each observation in our dataset would represent one sample of text from a book. Depending on our computational limitations, we may use larger or smaller samples from books.\n",
    "\n",
    "[Project Gutenberg](https://www.gutenberg.org/) is an online library that hosts a collection of over 70,000 free, open-access ebooks for which copyrights have expired. The platform includes books from a large span of time, with some being from hundreds of years ago. For each book, Project Gutenberg also stores metadata such as author (with year of birth/death), title, language, subject, class, and release date. Some books have recorded original publication dates, but not all. For books that do not have this variable, we may need to cross reference via another source.\n",
    "\n",
    "Project Gutenberg has a public API that should make it easy for us to work with their data. Provided that no issues arise with using this API, we should be able to move forward with this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan on gathering our data from [Project Gutenberg](https://www.gutenberg.org/), where all books published onto the website have their US copyright expired. A potential bias with the dataset is the type of books that are collected from scraping the website. To elaborate, books are added based on community input, thus only certain books are added and we are limited to what is available. Adding onto this, since we cannot feasibly scrape every single book from the website, only the most recently added books will be scraped, leaving behind the books that have been added for some time. While we cannot control what gets onto the website, we can randomly sample in order to include more works that were added further back in time rather than only those that were added recently. All books that are on Project Gutenberg are [free to use however the user sees fit](https://www.gutenberg.org/policy/permission.html) and therefore, will not be a problem in regards to data privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project, we expect a few but essential things from all our group members. We expect all group members to equally contribute to the best of their ability to the project. This project is a team effort, and everyone has something to contribute, whether they realize it or not. We also expect all members to attend weekly meetings at the time that we have already agreed and established. We expect everyone to stay in close communication via either Discord or the text chat that we have created. Any problems, concerns, or ideas that come up should be swiftly communicated via either of these channels. We intend to uphold these expectations not only to create an outstanding final product but also to alleviate any stress that can potentially be allocated to other team members. We are all in this together until the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 10/30 | 4:30pm | Brainstorm Topic/Data Question ideas | Discuss background experience; determine data science question; begin background research and working of project proposal |\n",
    "| 11/01 | 4:30pm | Finish project proposal | Confirm progress on project proposal, edit proposal as needed, and submit. |\n",
    "| 11/06 | 4:30pm | Begin looking at Project Gutenberg API. Cross-reference data in Project Gutenberg to ensure dates are correct. If possible, begin importing and cleaning data. | Discuss any issues that may arise from the dataset. Assign group members to specific parts of work; discuss wrangling and other possible analytical approaches. |\n",
    "| 11/13 | 4:30pm | Import and clean data from API; (Randomly pull excerpts from each book as well as author birth year); Write report for **Checkpoint 1: Data** | Review dataset and discuss any complications that arose from importing and cleaning data; Turn in **Checkpoint 1: Data** |\n",
    "| 11/20 | 4:30pm | EDA and Analysis (potentially model training) | Review EDA and analysis |\n",
    "| 11/27 | 4:30pm | Model Training and Analysis; Finish Report for **Checkpoint 2: EDA** | Review Model Training and Analysis; look at any mistakes or obstacles that occurred and discuss ways of correcting them. Turn in **Checkpoint 2: EDA** |\n",
    "| 12/04 | 4:30pm | Complete Analysis; Begin drafting results, conclusions, and discussion; If possible, work on Final project Presentation/**Final Project Report** | Review, edit, and finalize project report. Record Project Presentation if possible |\n",
    "| 12/11 | 4:30pm | Finish project presentation and record project presentation video parts (if needed) | Turn in **Final Project Report**/Final Project and Group Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
